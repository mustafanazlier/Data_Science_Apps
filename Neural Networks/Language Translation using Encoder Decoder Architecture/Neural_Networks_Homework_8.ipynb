{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural-Networks-Homework-8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kG_kcvBbND-"
      },
      "source": [
        "# Neural Networks Homework 8 - Encoder Decoder Language Translation\n",
        "\n",
        "## Mustafa Nazlıer - 15050111035"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f32HB1BFbit-"
      },
      "source": [
        "**In this implementation, I will be trying to commentate and improve the structure of the code written by Krish Naik**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lltBfmLQb7_l"
      },
      "source": [
        "**Importing the necessary network layers for the implementation -> Input layer, Long Short-Term Memory Layer and Dense layer type. We also could have use Gated Recurrence Unit Layers(GRU) **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em1Dh7wBYJLP",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "4df5d3bb-144a-4aea-a9ee-a8b513f195df"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np              \n",
        "from google.colab import files   #This was not present in the original code, I am using google colab to run the code, \n",
        "                                 #that is why I will be using this library to upload the 'fra.txt'\n",
        "\n",
        "\n",
        "uploaded = files.upload()    #this will open a section for me to upload the file to the environment\n",
        "                            #If you are going to use Jupyter lab, delete this part and add your file path to the below 'with open('yourPath/fra.txt', 'r' , encoding='utf-8') as f:"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7afcd86-52e2-4bec-b918-fbcc82b6c559\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e7afcd86-52e2-4bec-b918-fbcc82b6c559\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkbz_WX_dqRD"
      },
      "source": [
        "### Data preprocessing and vectorizing\n",
        "**In this part, we will be reading our file line by line and get the necessary parts which is splitted by a tab '\\t'. In the file fra.txt, there are also unnecessary information like (word   word_in_french and the rest of the line is needless data). That is why we are parsing the file using this below for loops **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDkoz3Q1aWHm"
      },
      "source": [
        "input_texts=[]        #english word\n",
        "target_texts=[]       #french translation of the particular english word\n",
        "\n",
        "num_samples=10000\n",
        "\n",
        "input_characters= set()\n",
        "target_characters= set()\n",
        "\n",
        "with open('fra.txt', 'r' , encoding='utf-8') as f:          \n",
        "    lines = f.read().split('\\n')\n",
        "for line in lines[:min(num_samples,len(lines)-1)]:\n",
        "    input_text, target_text, _ =line.split('\\t')\n",
        "    target_text= '\\t'+ target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "\n",
        "input_characters = sorted(list(input_characters))        #Every possible character that is used in the english words in the file\n",
        "target_characters = sorted(list(target_characters))      #Every possible character that is in the french version of the english words\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length= max([len(txt) for txt in input_texts])     \n",
        "max_decoder_seq_length= max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di1cQiblm45B",
        "outputId": "0579044d-fd29-4011-9c8e-50c15ef6e715"
      },
      "source": [
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:',max_decoder_seq_length)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 71\n",
            "Number of unique output tokens: 92\n",
            "Max sequence length for inputs: 15\n",
            "Max sequence length for outputs: 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vFAH6-YgY-K"
      },
      "source": [
        "### Vectorizing our input and target characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFGbDbM1noWK"
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char,i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char,i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYTK3JWyn9Q5",
        "outputId": "0273688d-2b40-47ba-edf5-15e440d431dc"
      },
      "source": [
        "print('Input tokens indexed',input_token_index.keys())\n",
        "print('Target tokens indexed', target_token_index.keys())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input tokens indexed dict_keys([' ', '!', '\"', '$', '%', '&', \"'\", ',', '-', '.', '0', '1', '2', '3', '5', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é'])\n",
            "Target tokens indexed dict_keys(['\\t', '\\n', ' ', '!', '%', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '5', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '«', '»', 'À', 'Ç', 'É', 'Ê', 'à', 'â', 'ç', 'è', 'é', 'ê', 'î', 'ï', 'ô', 'ù', 'û', 'œ', '\\u2009', '’', '\\u202f'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O8ngx8KjmAY"
      },
      "source": [
        "#### Creating my input and target data dimensions for the encoder decoder architecture, notice that there is no encoder output, it is because our output from the encoders will be in the last one as states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHtCjCojoOER"
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    ( len(input_texts), max_encoder_seq_length,num_encoder_tokens),       #dimensions for the english\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    ( len(input_texts), max_decoder_seq_length,num_decoder_tokens),       #dimensions for the french\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    ( len(input_texts), max_decoder_seq_length,num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1_CixGVtW1o"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts,target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.                                    #We make\n",
        "    for t, char in enumerate(target_text):                                                        #decoder target data is one timestep(in our case a char) \n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.                                   #ahead of decoder input data\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t-1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t+1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcmjKDSVluj5"
      },
      "source": [
        "### Creating the LSTM layer architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZm22ZMiQDe6"
      },
      "source": [
        "\n",
        "latent_dim=256    #\n",
        "\n",
        "encoder_inputs=Input(shape=(None,num_encoder_tokens))\n",
        "encoder =LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)      # We will not be using the encoder outputs because in encoder decoder architecture, the information we need is \n",
        "                                                                 # in the states. Outputs from each encoder flows through the encoders to form the states that we are going to pass\n",
        "encoder_states = [state_h, state_c]                              # through the decoder part\n",
        "\n",
        "decoder_inputs= Input(shape=(None,num_decoder_tokens))\n",
        "decoder_lstm=LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense (decoder_outputs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYNu-vnUnYpK"
      },
      "source": [
        "### Creating our model that includes the LTSM that we specified "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhUl8MPYQqow",
        "outputId": "0d40be39-ce65-4cae-8562-28e646f88d44"
      },
      "source": [
        "batch_size=64   ## batch size for the network\n",
        "epochs=100      ## epoch number                                       \n",
        "\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit([encoder_input_data,decoder_input_data], decoder_target_data, batch_size= batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 26s 48ms/step - loss: 1.4955 - accuracy: 0.7059 - val_loss: 1.1220 - val_accuracy: 0.7194\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.8757 - accuracy: 0.7642 - val_loss: 0.8272 - val_accuracy: 0.7690\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.6928 - accuracy: 0.8073 - val_loss: 0.6960 - val_accuracy: 0.7991\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.5908 - accuracy: 0.8289 - val_loss: 0.6425 - val_accuracy: 0.8137\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.5356 - accuracy: 0.8435 - val_loss: 0.5843 - val_accuracy: 0.8300\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.4984 - accuracy: 0.8537 - val_loss: 0.5585 - val_accuracy: 0.8359\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.4666 - accuracy: 0.8621 - val_loss: 0.5353 - val_accuracy: 0.8416\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.4463 - accuracy: 0.8675 - val_loss: 0.5166 - val_accuracy: 0.8479\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.4230 - accuracy: 0.8731 - val_loss: 0.5096 - val_accuracy: 0.8496\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.4073 - accuracy: 0.8776 - val_loss: 0.4917 - val_accuracy: 0.8549\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3900 - accuracy: 0.8825 - val_loss: 0.4849 - val_accuracy: 0.8570\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3713 - accuracy: 0.8880 - val_loss: 0.4789 - val_accuracy: 0.8595\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3575 - accuracy: 0.8922 - val_loss: 0.4679 - val_accuracy: 0.8632\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3431 - accuracy: 0.8964 - val_loss: 0.4613 - val_accuracy: 0.8645\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3309 - accuracy: 0.8999 - val_loss: 0.4558 - val_accuracy: 0.8662\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3205 - accuracy: 0.9037 - val_loss: 0.4553 - val_accuracy: 0.8665\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.3069 - accuracy: 0.9073 - val_loss: 0.4488 - val_accuracy: 0.8683\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2944 - accuracy: 0.9115 - val_loss: 0.4440 - val_accuracy: 0.8709\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2869 - accuracy: 0.9134 - val_loss: 0.4497 - val_accuracy: 0.8708\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2748 - accuracy: 0.9171 - val_loss: 0.4432 - val_accuracy: 0.8718\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2626 - accuracy: 0.9205 - val_loss: 0.4469 - val_accuracy: 0.8734\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2558 - accuracy: 0.9229 - val_loss: 0.4440 - val_accuracy: 0.8739\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2503 - accuracy: 0.9241 - val_loss: 0.4432 - val_accuracy: 0.8739\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2393 - accuracy: 0.9274 - val_loss: 0.4504 - val_accuracy: 0.8730\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2314 - accuracy: 0.9297 - val_loss: 0.4490 - val_accuracy: 0.8740\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2217 - accuracy: 0.9324 - val_loss: 0.4530 - val_accuracy: 0.8734\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2174 - accuracy: 0.9338 - val_loss: 0.4554 - val_accuracy: 0.8744\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2082 - accuracy: 0.9373 - val_loss: 0.4508 - val_accuracy: 0.8759\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.2012 - accuracy: 0.9386 - val_loss: 0.4599 - val_accuracy: 0.8750\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1962 - accuracy: 0.9401 - val_loss: 0.4641 - val_accuracy: 0.8752\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1885 - accuracy: 0.9424 - val_loss: 0.4625 - val_accuracy: 0.8754\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1851 - accuracy: 0.9437 - val_loss: 0.4721 - val_accuracy: 0.8748\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1780 - accuracy: 0.9457 - val_loss: 0.4757 - val_accuracy: 0.8745\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1749 - accuracy: 0.9466 - val_loss: 0.4741 - val_accuracy: 0.8753\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1678 - accuracy: 0.9488 - val_loss: 0.4711 - val_accuracy: 0.8774\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1628 - accuracy: 0.9503 - val_loss: 0.4859 - val_accuracy: 0.8746\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1548 - accuracy: 0.9521 - val_loss: 0.4879 - val_accuracy: 0.8747\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1524 - accuracy: 0.9535 - val_loss: 0.4918 - val_accuracy: 0.8762\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1496 - accuracy: 0.9547 - val_loss: 0.4923 - val_accuracy: 0.8755\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1438 - accuracy: 0.9563 - val_loss: 0.5007 - val_accuracy: 0.8759\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1403 - accuracy: 0.9573 - val_loss: 0.5046 - val_accuracy: 0.8748\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1380 - accuracy: 0.9578 - val_loss: 0.5082 - val_accuracy: 0.8756\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1330 - accuracy: 0.9592 - val_loss: 0.5148 - val_accuracy: 0.8756\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1299 - accuracy: 0.9600 - val_loss: 0.5171 - val_accuracy: 0.8748\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1260 - accuracy: 0.9614 - val_loss: 0.5241 - val_accuracy: 0.8747\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1247 - accuracy: 0.9620 - val_loss: 0.5279 - val_accuracy: 0.8749\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1207 - accuracy: 0.9628 - val_loss: 0.5351 - val_accuracy: 0.8745\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1158 - accuracy: 0.9648 - val_loss: 0.5349 - val_accuracy: 0.8757\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1135 - accuracy: 0.9649 - val_loss: 0.5428 - val_accuracy: 0.8747\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1108 - accuracy: 0.9657 - val_loss: 0.5452 - val_accuracy: 0.8753\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1091 - accuracy: 0.9665 - val_loss: 0.5504 - val_accuracy: 0.8758\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1067 - accuracy: 0.9672 - val_loss: 0.5547 - val_accuracy: 0.8736\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.1042 - accuracy: 0.9680 - val_loss: 0.5610 - val_accuracy: 0.8746\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.1023 - accuracy: 0.9686 - val_loss: 0.5663 - val_accuracy: 0.8741\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0986 - accuracy: 0.9696 - val_loss: 0.5706 - val_accuracy: 0.8748\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0965 - accuracy: 0.9702 - val_loss: 0.5780 - val_accuracy: 0.8742\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0941 - accuracy: 0.9707 - val_loss: 0.5846 - val_accuracy: 0.8736\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0931 - accuracy: 0.9707 - val_loss: 0.5831 - val_accuracy: 0.8737\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0913 - accuracy: 0.9710 - val_loss: 0.5896 - val_accuracy: 0.8740\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0895 - accuracy: 0.9720 - val_loss: 0.5909 - val_accuracy: 0.8737\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0868 - accuracy: 0.9724 - val_loss: 0.6051 - val_accuracy: 0.8728\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0855 - accuracy: 0.9733 - val_loss: 0.6048 - val_accuracy: 0.8728\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0833 - accuracy: 0.9735 - val_loss: 0.6046 - val_accuracy: 0.8734\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.0819 - accuracy: 0.9739 - val_loss: 0.6102 - val_accuracy: 0.8732\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0804 - accuracy: 0.9744 - val_loss: 0.6205 - val_accuracy: 0.8723\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0788 - accuracy: 0.9748 - val_loss: 0.6265 - val_accuracy: 0.8734\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0780 - accuracy: 0.9752 - val_loss: 0.6230 - val_accuracy: 0.8732\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0760 - accuracy: 0.9753 - val_loss: 0.6280 - val_accuracy: 0.8723\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0742 - accuracy: 0.9766 - val_loss: 0.6306 - val_accuracy: 0.8731\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0732 - accuracy: 0.9764 - val_loss: 0.6388 - val_accuracy: 0.8725\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0714 - accuracy: 0.9769 - val_loss: 0.6450 - val_accuracy: 0.8723\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0706 - accuracy: 0.9771 - val_loss: 0.6435 - val_accuracy: 0.8729\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0689 - accuracy: 0.9778 - val_loss: 0.6477 - val_accuracy: 0.8726\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0674 - accuracy: 0.9782 - val_loss: 0.6585 - val_accuracy: 0.8714\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0669 - accuracy: 0.9782 - val_loss: 0.6518 - val_accuracy: 0.8728\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0655 - accuracy: 0.9786 - val_loss: 0.6654 - val_accuracy: 0.8717\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0647 - accuracy: 0.9790 - val_loss: 0.6661 - val_accuracy: 0.8728\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0632 - accuracy: 0.9793 - val_loss: 0.6700 - val_accuracy: 0.8729\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0614 - accuracy: 0.9799 - val_loss: 0.6699 - val_accuracy: 0.8739\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0601 - accuracy: 0.9799 - val_loss: 0.6742 - val_accuracy: 0.8728\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0598 - accuracy: 0.9801 - val_loss: 0.6849 - val_accuracy: 0.8714\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0586 - accuracy: 0.9804 - val_loss: 0.6819 - val_accuracy: 0.8723\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0583 - accuracy: 0.9808 - val_loss: 0.6900 - val_accuracy: 0.8725\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0569 - accuracy: 0.9809 - val_loss: 0.6926 - val_accuracy: 0.8719\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 0.6936 - val_accuracy: 0.8724\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0550 - accuracy: 0.9814 - val_loss: 0.7044 - val_accuracy: 0.8717\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0548 - accuracy: 0.9815 - val_loss: 0.7018 - val_accuracy: 0.8716\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0537 - accuracy: 0.9818 - val_loss: 0.7058 - val_accuracy: 0.8727\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.7108 - val_accuracy: 0.8719\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0521 - accuracy: 0.9824 - val_loss: 0.7119 - val_accuracy: 0.8713\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0513 - accuracy: 0.9825 - val_loss: 0.7158 - val_accuracy: 0.8719\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0510 - accuracy: 0.9825 - val_loss: 0.7185 - val_accuracy: 0.8721\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0489 - accuracy: 0.9831 - val_loss: 0.7280 - val_accuracy: 0.8705\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 0.7260 - val_accuracy: 0.8717\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.7313 - val_accuracy: 0.8719\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0481 - accuracy: 0.9833 - val_loss: 0.7299 - val_accuracy: 0.8722\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0473 - accuracy: 0.9835 - val_loss: 0.7385 - val_accuracy: 0.8708\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.0465 - accuracy: 0.9840 - val_loss: 0.7415 - val_accuracy: 0.8709\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0461 - accuracy: 0.9840 - val_loss: 0.7423 - val_accuracy: 0.8712\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.0456 - accuracy: 0.9840 - val_loss: 0.7475 - val_accuracy: 0.8713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe8b799c5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vNynaMNpEEy"
      },
      "source": [
        "### Generating the sentences "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpaymKE0pKZ_"
      },
      "source": [
        "Now that we have trained our network, we can now translate the fra English words into French by around %85 accuracy, of course it is far from perfect but given the simplicity of this implementation, It shows the vast promise of the Recurrent Neural Networks and the Encoder Decoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9m1ZDK2T9UH",
        "outputId": "ca715524-9bfc-4272-e34f-b4aad7057323"
      },
      "source": [
        "encoder_model= Model(encoder_inputs, encoder_states)            #Now using the trained model, we can feed a word into it and retrieve the achieved translation\n",
        "\n",
        "decoder_state_input_h= Input(shape=(latent_dim,))\n",
        "decoder_state_input_c= Input(shape=(latent_dim,))\n",
        "decoder_states_inputs= [decoder_state_input_h,decoder_state_input_c ]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states= [state_h, state_c]\n",
        "decoder_outputs= decoder_dense(decoder_outputs)\n",
        "decoder_model= Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "reverse_input_char_index= dict(\n",
        "    (i, char) for char, i in input_token_index.items())                  ##Revectorizing our data\n",
        "reverse_target_char_index= dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    states_value= encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))                 #Decoding a sentence\n",
        "\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition= False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h , c = decoder_model.predict([target_seq]+ states_value)\n",
        "\n",
        "\n",
        "        sampled_token_index= np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence+= sampled_char\n",
        "\n",
        "\n",
        "\n",
        "        if(sampled_char == '\\n' or len(decoded_sentence)> max_decoder_seq_length): \n",
        "            stop_condition= True\n",
        "\n",
        "        \n",
        "        target_seq= np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index]= 1.\n",
        "\n",
        "        states_value= [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "                                                                                     \n",
        "for seq_index in range(100):                                                  #Translating the first 100 words in the fra.txt by using the model\n",
        "                               \n",
        "    input_seq= encoder_input_data[seq_index: seq_index+1]\n",
        "    decoded_sentence= decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)\n",
        "     "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Marche.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Marche.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Marche.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: File !\n",
            "\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: Qui ?\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Ça alors !\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Au feu !\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Hide.\n",
            "Decoded sentence: Cachez-vous.\n",
            "\n",
            "-\n",
            "Input sentence: Hide.\n",
            "Decoded sentence: Cachez-vous.\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: Saute.\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Saute.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Arrête-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Arrête-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Arrête-toi !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Attends !\n",
            "\n",
            "-\n",
            "Input sentence: Begin.\n",
            "Decoded sentence: Commencez.\n",
            "\n",
            "-\n",
            "Input sentence: Begin.\n",
            "Decoded sentence: Commencez.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poursuivez.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poursuivez.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Poursuivez.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Bonjour !\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Bonjour !\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Est-ce gros e-t-er.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Est-ce gros e-t-er.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: J'essaye.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Je l'ai emporté !\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Je l'ai emporté !\n",
            "\n",
            "-\n",
            "Input sentence: I won.\n",
            "Decoded sentence: J’ai gagné.\n",
            "\n",
            "-\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: Oh non !\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Détends-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Souriez !\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Souriez !\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Souriez !\n",
            "\n",
            "-\n",
            "Input sentence: Sorry?\n",
            "Decoded sentence: Pardon ?\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Attaquez !\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Attaquez !\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Attaquez !\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-la !\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-la !\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-la !\n",
            "\n",
            "-\n",
            "Input sentence: Buy it.\n",
            "Decoded sentence: Achetez-la !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Merci !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Merci !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Merci !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Merci !\n",
            "\n",
            "-\n",
            "Input sentence: Eat it.\n",
            "Decoded sentence: Mangez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Eat it.\n",
            "Decoded sentence: Mangez-le.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Lève-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Lève-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Lève-toi.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Vas-y maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Vas-y maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Vas-y maintenant.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Compris !\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Compris !\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Compris !\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: T'as capté ?\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: T'as capté ?\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: T'as capté ?\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Montez.\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Montez.\n",
            "\n",
            "-\n",
            "Input sentence: Hug me.\n",
            "Decoded sentence: Serre-moi dans tes bras !\n",
            "\n",
            "-\n",
            "Input sentence: Hug me.\n",
            "Decoded sentence: Serre-moi dans tes bras !\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: Je suis tombée.\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: Je suis tombée.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jycJtfatf_w"
      },
      "source": [
        "### Improvements over the implementation\n",
        "#### I have tried changing  the activation function but the accuracy results were similar\n",
        "#### I believe the implementation is hard coded. We could have change the parsing style to make it more generic to adapt it into different input file styles\n",
        "#### Instead of LTSM, we could have use GRU and It would have an effect on the accuracy outcome \n",
        "#### I have tried to improve general structural quality bt adding sections and more understandable comments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hazOTZiK0KDD"
      },
      "source": [
        "Ps: I have used google colab in this homework, that is why I have added an upload section, to use it with jupyter lab, you can easily delete or comment that part and add your path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4jFwNFn0brQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}