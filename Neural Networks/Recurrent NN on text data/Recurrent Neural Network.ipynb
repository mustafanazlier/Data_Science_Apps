{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Neural Networks Homework 7",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpZyIhNIgoq"
      },
      "source": [
        "# Neural Networks Homework 7\n",
        "## Mustafa NazlÄ±er-15050111035"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyKZj3bzf9p"
      },
      "source": [
        "### Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD_55cOxLkAb"
      },
      "source": [
        "name_of_the_file = 'The_Call_of_Cthulhu.txt'   ## Defining the name for the input book The Call of Cthulhu by H.P. Lovecraft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "x6uVHIE4zNVv",
        "outputId": "57188699-9a55-4622-8615-974e5583ad58"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()             ## To upload our file to the environment, we will use 'files'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-503e4be3-1515-4ab9-9d75-5c7c06402100\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-503e4be3-1515-4ab9-9d75-5c7c06402100\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving The_Call_of_Cthulhu.txt to The_Call_of_Cthulhu (3).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavnuByVymwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0833ca8b-eefa-4692-b179-67dfba5443a9"
      },
      "source": [
        "\n",
        "text = open(name_of_the_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 69524 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duhg9NrUymwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f12764-7f4c-45f3-b3e6-31db6691254e"
      },
      "source": [
        "# First 500 characters in the text\n",
        "print(text[:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Call of Cthulhu\n",
            "\n",
            "by H. P. Lovecraft\n",
            "\n",
            "Written Summer 1926\n",
            "\n",
            "Published February 1928 in Weird Tales, Vol. 11, No. 2, p. 159-78, 287.\n",
            "\n",
            "Of such great powers or beings there may be conceivably a survivalâ¦ a survival of a hugely remote period whenâ¦ consciousness was manifested, perhaps, in shapes and forms long since withdrawn before the tide of advancing humanityâ¦ forms of which poetry and legend alone have caught a flying memory and called them gods, monsters, mythical beings of all sorts and kin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OIVMENmqzhW"
      },
      "source": [
        "#Data Preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCgQBRVymwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1773a5e6-6ff7-447a-8080-13a2b8b79843"
      },
      "source": [
        "    \n",
        "text=re.sub('[^A-Za-z]+', ' ', text).strip().lower() \n",
        "print(text[:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the call of cthulhu by h p lovecraft written summer published february in weird tales vol no p of such great powers or beings there may be conceivably a survival a survival of a hugely remote period when consciousness was manifested perhaps in shapes and forms long since withdrawn before the tide of advancing humanity forms of which poetry and legend alone have caught a flying memory and called them gods monsters mythical beings of all sorts and kinds algernon blackwood i the horror in clay the \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXfTjpKUqc4w",
        "outputId": "5ed8d8f3-8df9-4037-ae48-e2d32d933afd"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GMlCe3qzaL9"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2m3mqkDjRj"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5apvBDn9Ind"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UopbsKi88tm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483d5692-0fd5-4b67-d2cc-35e23596102d"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(67836,), dtype=int64, numpy=array([21,  9,  6, ...,  6, 26,  6])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmxrYDCTy-eL"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjH5v45-yqqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44819335-7399-4273-f21c-c830774662f5"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "c\n",
            "a\n",
            "l\n",
            "l\n",
            " \n",
            "o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-G2oaTxy6km"
      },
      "source": [
        "seq_length = 200\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpdjRO2CzOfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c6eb2d-c695-4f5f-b088-ab357d8e232a"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b't' b'h' b'e' b' ' b'c' b'a' b'l' b'l' b' ' b'o' b'f' b' ' b'c' b't'\n",
            " b'h' b'u' b'l' b'h' b'u' b' ' b'b' b'y' b' ' b'h' b' ' b'p' b' ' b'l'\n",
            " b'o' b'v' b'e' b'c' b'r' b'a' b'f' b't' b' ' b'w' b'r' b'i' b't' b't'\n",
            " b'e' b'n' b' ' b's' b'u' b'm' b'm' b'e' b'r' b' ' b'p' b'u' b'b' b'l'\n",
            " b'i' b's' b'h' b'e' b'd' b' ' b'f' b'e' b'b' b'r' b'u' b'a' b'r' b'y'\n",
            " b' ' b'i' b'n' b' ' b'w' b'e' b'i' b'r' b'd' b' ' b't' b'a' b'l' b'e'\n",
            " b's' b' ' b'v' b'o' b'l' b' ' b'n' b'o' b' ' b'p' b' ' b'o' b'f' b' '\n",
            " b's' b'u' b'c' b'h' b' ' b'g' b'r' b'e' b'a' b't' b' ' b'p' b'o' b'w'\n",
            " b'e' b'r' b's' b' ' b'o' b'r' b' ' b'b' b'e' b'i' b'n' b'g' b's' b' '\n",
            " b't' b'h' b'e' b'r' b'e' b' ' b'm' b'a' b'y' b' ' b'b' b'e' b' ' b'c'\n",
            " b'o' b'n' b'c' b'e' b'i' b'v' b'a' b'b' b'l' b'y' b' ' b'a' b' ' b's'\n",
            " b'u' b'r' b'v' b'i' b'v' b'a' b'l' b' ' b'a' b' ' b's' b'u' b'r' b'v'\n",
            " b'i' b'v' b'a' b'l' b' ' b'o' b'f' b' ' b'a' b' ' b'h' b'u' b'g' b'e'\n",
            " b'l' b'y' b' ' b'r' b'e' b'm' b'o' b't' b'e' b' ' b'p' b'e' b'r' b'i'\n",
            " b'o' b'd' b' ' b'w' b'h'], shape=(201,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO32cMWu4a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2da07e8-ea22-4abe-e363-1a970d907de8"
      },
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'the call of cthulhu by h p lovecraft written summer published february in weird tales vol no p of such great powers or beings there may be conceivably a survival a survival of a hugely remote period wh'\n",
            "b'en consciousness was manifested perhaps in shapes and forms long since withdrawn before the tide of advancing humanity forms of which poetry and legend alone have caught a flying memory and called them'\n",
            "b' gods monsters mythical beings of all sorts and kinds algernon blackwood i the horror in clay the most merciful thing in the world i think is the inability of the human mind to correlate all its conten'\n",
            "b'ts we live on a placid island of ignorance in the midst of black seas of infinity and it was not meant that we should voyage far the sciences each straining in its own direction have hitherto harmed us'\n",
            "b' little but some day the piecing together of dissociated knowledge will open up such terrifying vistas of reality and of our frightful position therein that we shall either go mad from the revelation o'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9iKPXkw5xwa"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996f47bd-ec2a-41f7-e254-a1892f1d4f0b"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):         #shifting\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'the call of cthulhu by h p lovecraft written summer published february in weird tales vol no p of such great powers or beings there may be conceivably a survival a survival of a hugely remote period w'\n",
            "Target: b'he call of cthulhu by h p lovecraft written summer published february in weird tales vol no p of such great powers or beings there may be conceivably a survival a survival of a hugely remote period wh'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdfPmdqzf-R"
      },
      "source": [
        "### Create training sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2pGotuNzf-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1db5a4c-5541-4ee4-8f23-d3325cc7b6e7"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        " \n",
        "BUFFER_SIZE = 10000      #to shuffle the dataset\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 200), (64, 200)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj8HQ2w8z4iO"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):                       #RNN model\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,                                   #long products of matrices can lead to vanishing or exploding gradients, Gated Recurrent Units is a \n",
        "                                   return_sequences=True,                       #way to handle this type of anomalies, there are also Long Short-Term Memory(LSTM)\n",
        "                                   return_state=True)                                \n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX58Xj9z47Aw"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkA5upJIJ7W7"
      },
      "source": [
        "For each character the model looks up the embedding, runs the GRU one timestep with the embedding as input, and applies the dense layer to generate logits predicting the log-likelihood of the next character:\n",
        "\n",
        "![A drawing of the data passing through the model](https://github.com/tensorflow/text/blob/master/docs/tutorials/images/text_generation_training.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-_70kKAPrPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98918a43-7474-414a-cd2e-1b552673a7ce"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 200, 28) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NzLBi4VM4o"
      },
      "source": [
        "In the above example the sequence length of the input is `100` but the model can be run on inputs of any length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bdd3ff5-b376-4dbd-f6db-0fdd220014ec"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  7168      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  28700     \n",
            "=================================================================\n",
            "Total params: 3,974,172\n",
            "Trainable params: 3,974,172\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqFMUQc_UFgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1102d27d-342f-474c-b6cc-265c3e85b8bb"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  1, 21, 10, 22, 22,  9, 17, 25, 25, 24, 16, 20, 25,  8, 22, 24,\n",
              "       26,  4, 18,  1, 10, 16, 16, 21, 24, 26, 19, 16, 16, 25, 20, 21, 24,\n",
              "       14, 20,  5, 25,  8, 11, 21, 26, 19, 13, 10, 14,  5, 23, 16, 13, 19,\n",
              "       25, 20, 20, 16,  9,  0,  0, 21, 17, 10, 11, 11, 17, 13,  2, 17, 10,\n",
              "       10, 23,  5, 27,  9, 25,  0, 17,  8,  1, 26,  9, 23,  4, 25, 23, 20,\n",
              "        9, 20,  8,  1, 21, 22,  3, 27,  4, 19, 11,  8, 27, 27,  1,  9,  7,\n",
              "        0, 21,  3, 23,  0,  0,  3,  5,  7,  8, 16, 20,  0,  8, 20, 21,  5,\n",
              "       18, 24, 18, 17, 25,  3, 17, 25, 22,  0, 25,  6, 16, 21, 22, 19, 23,\n",
              "        3, 25,  0, 25,  8, 24, 27,  9, 17, 14, 15, 12, 21, 13, 26, 19,  3,\n",
              "       24, 17,  6, 19,  4,  3, 23, 27, 14, 20, 16, 16, 23, 15, 11, 14, 20,\n",
              "        7,  0,  7,  3, 20,  5, 13,  4, 16, 22,  1, 18,  4, 16,  5,  3,  2,\n",
              "       17, 21, 12, 26, 24,  8, 15, 11, 15,  3,  8, 21, 19])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWcFwPwLSo05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6e3153-b8a9-4ed3-d1c6-6511c0614a26"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'able from any local source his name was john raymond legrasse and he was by profession an inspector of police with him he bore the subject of his visit a grotesque repulsive and apparently very ancien'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'b tiuuhpxxwosxguwycq iootwyrooxstwmsdxgjtyrlimdvolrxssoh[UNK][UNK]tpijjplapiivdzhx[UNK]pg yhvcxvshsg tubzcrjgzz hf[UNK]tbv[UNK][UNK]bdfgos[UNK]gstdqwqpxbpxu[UNK]xeoturvbx[UNK]xgwzhpmnktlyrbwpercbvzmsoovnjmsf[UNK]fbsdlcou qcodbaptkywgnjnbgtr'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trpqTWyvk0nr"
      },
      "source": [
        "### Attach an optimizer, and a loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ky3F_BhgkTW"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "source": [
        "EPOCHS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK-hmKjYVoll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d441b6-1c5c-4fd1-e0b3-7d9ef6d19a90"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 2s 108ms/step - loss: 4.3485 - accuracy: 0.1456\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 1s 95ms/step - loss: 3.1252 - accuracy: 0.1966\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 1s 96ms/step - loss: 3.1667 - accuracy: 0.2115\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 1s 96ms/step - loss: 3.0880 - accuracy: 0.1960\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.9125 - accuracy: 0.1420\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 1s 96ms/step - loss: 2.7591 - accuracy: 0.1890\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.7040 - accuracy: 0.2041\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.6227 - accuracy: 0.2470\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.5492 - accuracy: 0.2730\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.4784 - accuracy: 0.2888\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 1s 96ms/step - loss: 2.4202 - accuracy: 0.2945\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.3783 - accuracy: 0.2996\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 1s 96ms/step - loss: 2.3441 - accuracy: 0.3005\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.3136 - accuracy: 0.3078\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 1s 96ms/step - loss: 2.2878 - accuracy: 0.3161\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 1s 96ms/step - loss: 2.2670 - accuracy: 0.3201\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 1s 96ms/step - loss: 2.2460 - accuracy: 0.3248\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 1s 96ms/step - loss: 2.2266 - accuracy: 0.3304\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.2125 - accuracy: 0.3347\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.1973 - accuracy: 0.3418\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.1804 - accuracy: 0.3461\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.1682 - accuracy: 0.3477\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.1552 - accuracy: 0.3496\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.1418 - accuracy: 0.3531\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.1256 - accuracy: 0.3583\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.1105 - accuracy: 0.3634\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.0936 - accuracy: 0.3698\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.0800 - accuracy: 0.3762\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.0637 - accuracy: 0.3816\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 1s 97ms/step - loss: 2.0489 - accuracy: 0.3838\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.0321 - accuracy: 0.3884\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 2.0135 - accuracy: 0.3910\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 1.9970 - accuracy: 0.3964\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.9767 - accuracy: 0.4033\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.9632 - accuracy: 0.4055\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.9454 - accuracy: 0.4128\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.9264 - accuracy: 0.4186\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.9097 - accuracy: 0.4224\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.8926 - accuracy: 0.4273\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 1.8754 - accuracy: 0.4327\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.8564 - accuracy: 0.4402\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 1.8362 - accuracy: 0.4436\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 1.8187 - accuracy: 0.4499\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.7993 - accuracy: 0.4564\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.7812 - accuracy: 0.4613\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.7601 - accuracy: 0.4685\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.7422 - accuracy: 0.4734\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.7253 - accuracy: 0.4763\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.7082 - accuracy: 0.4811\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.6885 - accuracy: 0.4860\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.6659 - accuracy: 0.4938\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.6485 - accuracy: 0.4971\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 1.6275 - accuracy: 0.5038\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.6109 - accuracy: 0.5101\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 1.5869 - accuracy: 0.5152\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.5711 - accuracy: 0.5220\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.5483 - accuracy: 0.5280\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 1.5282 - accuracy: 0.5341\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 1.5091 - accuracy: 0.5410\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.4876 - accuracy: 0.5466\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 1.4630 - accuracy: 0.5541\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.4422 - accuracy: 0.5617\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.4224 - accuracy: 0.5670\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.3998 - accuracy: 0.5742\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.3762 - accuracy: 0.5815\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.3543 - accuracy: 0.5868\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.3298 - accuracy: 0.5960\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 1.3061 - accuracy: 0.6027\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 1.2833 - accuracy: 0.6090\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 1.2628 - accuracy: 0.6161\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 1.2387 - accuracy: 0.6230\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 1.2132 - accuracy: 0.6314\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 1.1888 - accuracy: 0.6388\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 1.1621 - accuracy: 0.6473\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 1.1400 - accuracy: 0.6541\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 1.1114 - accuracy: 0.6641\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 1.0852 - accuracy: 0.6733\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 1.0565 - accuracy: 0.6830\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 1.0280 - accuracy: 0.6916\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 1.0003 - accuracy: 0.7028\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 0.9705 - accuracy: 0.7127\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.9417 - accuracy: 0.7240\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 0.9108 - accuracy: 0.7329\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.8823 - accuracy: 0.7430\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.8571 - accuracy: 0.7509\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.8233 - accuracy: 0.7649\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.7914 - accuracy: 0.7759\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 0.7610 - accuracy: 0.7884\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.7254 - accuracy: 0.8010\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.6978 - accuracy: 0.8099\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.6675 - accuracy: 0.8217\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.6379 - accuracy: 0.8324\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.6051 - accuracy: 0.8430\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.5727 - accuracy: 0.8566\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 0.5487 - accuracy: 0.8652\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.5126 - accuracy: 0.8795\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.4858 - accuracy: 0.8878\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.4570 - accuracy: 0.8992\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 1s 100ms/step - loss: 0.4335 - accuracy: 0.9070\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.4056 - accuracy: 0.9170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSBU1tHmlUSs"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqMOuDutnOxK"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST7PSyk9t1mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579c1c2f-c50a-4a55-89c7-a4aa1578b3a3"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Generated text:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated text:o custan were but before the teorrible formid with fir the great noce op and toward their dast socting buriad the figurat of all eshand be asponith in durady talfional forw for some from smow heard the woods it was the police all its contence asticts and older thing whilst it was vanusce whose gohe puriary with heart with their kestly with untomn before the eddor mound at the delebreice and in a small manuscript earer was belink sidce of men a boom of mether of his visitation as what ha untlamented professor in mighty but before the worded older that its mounten whor him exlide after ot provinged the first men commor to men from inlisine subes of the baser abterroly the lixed blad oldres and his men were aithone was at lystiag of porears that eared baight in the sunsain see mugh nearly slofe therrible voodeous res guling about fit as it was i hade cthulhu untlem recelt and april ndatus of hangested up at aly profted went no mighty and i recomental interest futhismed with its delice rep \n",
            "\n",
            "________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP65JniaLNk-"
      },
      "source": [
        "##Additional example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuL3BjFwLPTk"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIr7VGh-LQzE"
      },
      "source": [
        "##AS an example for to many to one implementation, I have also added to this short part to our lab, this is text classification using an embedding and a LSTM layer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djmONmUDLRUB"
      },
      "source": [
        "\n",
        "class TextRNN(Model):\n",
        "    def __init__(self,\n",
        "                 maxlen,\n",
        "                 max_features,\n",
        "                 embedding_dims,\n",
        "                 class_num=1,\n",
        "                 last_activation='sigmoid'):\n",
        "        super(TextRNN, self).__init__()\n",
        "        self.maxlen = maxlen\n",
        "        self.max_features = max_features\n",
        "        self.embedding_dims = embedding_dims\n",
        "        self.class_num = class_num\n",
        "        self.last_activation = last_activation\n",
        "        self.embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen)\n",
        "        self.rnn = LSTM(128)  # LSTM or GRU\n",
        "        self.classifier = Dense(self.class_num, activation=self.last_activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if len(inputs.get_shape()) != 2:\n",
        "            raise ValueError('The rank of inputs of TextRNN must be 2, but now is %d' % len(inputs.get_shape()))\n",
        "        if inputs.get_shape()[1] != self.maxlen:\n",
        "            raise ValueError('The maxlen of inputs of TextRNN must be %d, but now is %d' % (self.maxlen, inputs.get_shape()[1]))\n",
        "        embedding = self.embedding(inputs)\n",
        "        x = self.rnn(embedding)\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgKpmMMbLTjd",
        "outputId": "207df3e6-50f2-4144-9215-17a64f5fef41"
      },
      "source": [
        "import timeit\n",
        "\n",
        "max_features = 5000\n",
        "maxlen = 400\n",
        "batch_size = 32\n",
        "embedding_dims = 50\n",
        "epochs = 10\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)...')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Build model...')\n",
        "model = TextRNN(maxlen, max_features, embedding_dims)\n",
        "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, mode='max')\n",
        "%time h =  model.fit(x_train, y_train, batch_size=batch_size,epochs=epochs, callbacks=[early_stopping], validation_data=(x_test, y_test))\n",
        "                \n",
        "               \n",
        "                \n",
        "\n",
        "print('Test...')\n",
        "result = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)...\n",
            "x_train shape: (25000, 400)\n",
            "x_test shape: (25000, 400)\n",
            "Build model...\n",
            "Train...\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 28s 34ms/step - loss: 0.4755 - accuracy: 0.7676 - val_loss: 0.3701 - val_accuracy: 0.8435\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3260 - accuracy: 0.8646 - val_loss: 0.3535 - val_accuracy: 0.8524\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.2736 - accuracy: 0.8911 - val_loss: 0.3206 - val_accuracy: 0.8776\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.2191 - accuracy: 0.9149 - val_loss: 0.3272 - val_accuracy: 0.8752\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.1931 - accuracy: 0.9248 - val_loss: 0.4028 - val_accuracy: 0.8424\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.1655 - accuracy: 0.9384 - val_loss: 0.3678 - val_accuracy: 0.8736\n",
            "CPU times: user 2min 46s, sys: 6.25 s, total: 2min 53s\n",
            "Wall time: 2min 35s\n",
            "Test...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "LciP531sLVPU",
        "outputId": "f4fbf724-809b-4b6e-81c0-a0a2c6ce2c6a"
      },
      "source": [
        "pd.DataFrame(h.history).plot(figsize=(8, 5))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b2df5eb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}